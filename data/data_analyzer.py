"""
Analizador de Datos Integrado - SQL Server + Erlang C
"""

import pandas as pd
import numpy as np
from datetime import datetime, date, timedelta
from typing import Dict, List, Optional, Tuple
import logging
import sys
from pathlib import Path

# Agregar paths
sys.path.append(str(Path(__file__).parent.parent))

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(name)s:%(message)s')
logger = logging.getLogger(__name__)

try:
    from data.sql_connector import sql_connector
    from engines.erlang_calculator import erlang_calculator, ErlangInputs, ErlangResults
except ImportError as e:
    logger.error(f"âŒ Error importando mÃ³dulos: {e}")
    print(f"âŒ Error importando mÃ³dulos: {e}")
    exit(1)

class DataAnalyzer:
    """Analizador integrado de datos histÃ³ricos y dimensionamiento"""
    
    def __init__(self):
        self.sql_connector = sql_connector
        self.erlang_calculator = erlang_calculator
        
    def analyze_campaign_complete(self, 
                                 start_date: date, 
                                 end_date: date,
                                 sla_target: float = 0.90,
                                 answer_time_target: int = 20,
                                 shrinkage_pct: float = 15.0) -> Dict:
        """
        AnÃ¡lisis completo de campaÃ±a: datos histÃ³ricos + dimensionamiento + validaciÃ³n
        
        Args:
            start_date: Fecha inicio anÃ¡lisis
            end_date: Fecha fin anÃ¡lisis
            sla_target: Objetivo SLA (0.90 = 90%)
            answer_time_target: Tiempo respuesta objetivo en segundos
            shrinkage_pct: Porcentaje de shrinkage
            
        Returns:
            Dict con anÃ¡lisis completo
        """
        try:
            print(f"ğŸ” Iniciando anÃ¡lisis completo de campaÃ±a...")
            print(f"ğŸ“… PerÃ­odo: {start_date} - {end_date}")
            print(f"ğŸ¯ SLA objetivo: {sla_target*100}% en {answer_time_target}s")
            
            # 1. Obtener datos histÃ³ricos
            print("ğŸ“Š 1. Obteniendo datos histÃ³ricos...")
            df = self.sql_connector.get_campaign_data(start_date, end_date)
            
            if len(df) == 0:
                raise ValueError("No se encontraron datos para el perÃ­odo especificado")
            
            # 2. AnÃ¡lisis de datos histÃ³ricos
            print("ğŸ“ˆ 2. Analizando patrones histÃ³ricos...")
            historical_analysis = self.erlang_calculator.analyze_historical_data(df)
            
            # 3. AnÃ¡lisis por intervalos (hora pico vs promedio)
            print("â° 3. Analizando por intervalos...")
            interval_analysis = self._analyze_by_intervals(df)
            
            # 4. Dimensionamiento con Erlang C
            print("ğŸ§® 4. Calculando dimensionamiento...")
            dimensioning_results = self._calculate_dimensioning_scenarios(
                historical_analysis, interval_analysis, sla_target, answer_time_target, shrinkage_pct
            )
            
            # 5. ValidaciÃ³n contra TME real
            print("âœ… 5. Validando contra datos reales...")
            validation_results = self._validate_against_reality(df, dimensioning_results)
            
            # 6. Recomendaciones
            print("ğŸ’¡ 6. Generando recomendaciones...")
            recommendations = self._generate_recommendations(
                historical_analysis, dimensioning_results, validation_results
            )
            
            # 7. Compilar resultados finales
            complete_analysis = {
                'period': {
                    'start_date': start_date,
                    'end_date': end_date,
                    'days_analyzed': (end_date - start_date).days + 1
                },
                'targets': {
                    'sla_target': sla_target * 100,
                    'answer_time_target': answer_time_target,
                    'shrinkage_percentage': shrinkage_pct
                },
                'historical_analysis': historical_analysis,
                'interval_analysis': interval_analysis,
                'dimensioning_results': dimensioning_results,
                'validation_results': validation_results,
                'recommendations': recommendations,
                'summary': self._create_executive_summary(
                    historical_analysis, dimensioning_results, validation_results
                )
            }
            
            self._log_complete_results(complete_analysis)
            
            return complete_analysis
            
        except Exception as e:
            logger.error(f"âŒ Error en anÃ¡lisis completo: {e}")
            print(f"âŒ Error en anÃ¡lisis completo: {e}")
            raise
    
    def _analyze_by_intervals(self, df: pd.DataFrame) -> Dict:
        """AnÃ¡lisis detallado por intervalos de tiempo"""
        try:
            df['hora_inicio_contrata'] = pd.to_datetime(df['hora_inicio_contrata'])
            df['hora'] = df['hora_inicio_contrata'].dt.hour
            df['intervalo_15min'] = (df['hora_inicio_contrata'].dt.minute // 15) * 15
            
            # AnÃ¡lisis por hora - CORREGIDO: evitar duplicaciÃ³n de columnas
            hourly_stats = df.groupby('hora').agg({
                'asesor': ['count', 'nunique'],  # Llamadas y agentes Ãºnicos
                'tmo': ['mean', 'std'],
                'tme': ['mean', 'std']
            }).round(2)
            
            # Renombrar columnas con estructura jerÃ¡rquica corregida
            hourly_stats.columns = ['llamadas', 'agentes_activos', 'tmo_promedio', 'tmo_std', 'tme_promedio', 'tme_std']
            
            # Encontrar hora pico
            peak_hour = hourly_stats['llamadas'].idxmax()
            peak_volume = hourly_stats.loc[peak_hour, 'llamadas']
            
            # AnÃ¡lisis por intervalos de 15 minutos (hora pico)
            peak_hour_data = df[df['hora'] == peak_hour]
            interval_15min = peak_hour_data.groupby('intervalo_15min').agg({
                'asesor': 'count',
                'tmo': 'mean',
                'tme': 'mean'
            }).round(2)
            
            # Capturar TMO de hora pico para usar en escenarios
            peak_hour_tmo = float(hourly_stats.loc[peak_hour, 'tmo_promedio'])
            
            return {
                'hourly_profile': hourly_stats.to_dict('index'),
                'peak_hour': {
                    'hour': int(peak_hour),
                    'volume': int(peak_volume),
                    'tmo_avg': peak_hour_tmo,  # TMO especÃ­fico de hora pico
                    'tme_avg': float(hourly_stats.loc[peak_hour, 'tme_promedio']),
                    'agents_active': int(hourly_stats.loc[peak_hour, 'agentes_activos'])
                },
                'peak_hour_tmo': peak_hour_tmo,  # NUEVO: TMO especÃ­fico para escenarios
                'interval_15min_peak': interval_15min.to_dict('index'),
                'busiest_intervals': {
                    'top_3_hours': hourly_stats.nlargest(3, 'llamadas')[['llamadas', 'tmo_promedio']].to_dict('index')
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ Error en anÃ¡lisis por intervalos: {e}")
            return {}
    
    def _calculate_dimensioning_scenarios(self, historical_analysis: Dict, interval_analysis: Dict,
                                        sla_target: float, answer_time: int, 
                                        shrinkage_pct: float) -> Dict:
        """Calcular mÃºltiples escenarios de dimensionamiento"""
        try:
            scenarios = {}
            
            # Escenario 1: Promedio histÃ³rico
            avg_volume = historical_analysis['volume_analysis']['avg_calls_per_hour']
            avg_tmo = historical_analysis['tmo_analysis']['average_seconds']
            
            inputs_avg = ErlangInputs(
                calls_per_hour=avg_volume,
                average_handle_time=avg_tmo,
                service_level_target=sla_target,
                answer_time_target=answer_time,
                shrinkage_percentage=shrinkage_pct
            )
            
            scenarios['promedio'] = self.erlang_calculator.calculate_erlang_c(inputs_avg)
            
            # Escenario 2: Hora pico - CORREGIDO: usar TMO especÃ­fico de hora pico
            peak_volume = historical_analysis['volume_analysis']['peak_volume']
            # Obtener TMO de hora pico desde interval_analysis
            peak_tmo = interval_analysis.get('peak_hour_tmo', avg_tmo)  # Usar TMO especÃ­fico de hora pico
            
            inputs_peak = ErlangInputs(
                calls_per_hour=peak_volume,
                average_handle_time=peak_tmo,  # TMO especÃ­fico de hora pico
                service_level_target=sla_target,
                answer_time_target=answer_time,
                shrinkage_percentage=shrinkage_pct
            )
            
            scenarios['hora_pico'] = self.erlang_calculator.calculate_erlang_c(inputs_peak)
            
            # Escenario 3: Conservador (percentil 90 de volumen)
            hourly_volumes = list(historical_analysis['volume_analysis']['hourly_profile'].values())
            p90_volume = np.percentile(hourly_volumes, 90)
            
            inputs_conservative = ErlangInputs(
                calls_per_hour=p90_volume,
                average_handle_time=avg_tmo,
                service_level_target=sla_target,
                answer_time_target=answer_time,
                shrinkage_percentage=shrinkage_pct
            )
            
            scenarios['conservador'] = self.erlang_calculator.calculate_erlang_c(inputs_conservative)
            
            # Escenario 4: Optimista (percentil 75)
            p75_volume = np.percentile(hourly_volumes, 75)
            
            inputs_optimistic = ErlangInputs(
                calls_per_hour=p75_volume,
                average_handle_time=avg_tmo,
                service_level_target=sla_target,
                answer_time_target=answer_time,
                shrinkage_percentage=shrinkage_pct
            )
            
            scenarios['optimista'] = self.erlang_calculator.calculate_erlang_c(inputs_optimistic)
            
            return {
                'scenarios': {k: v.to_dict() for k, v in scenarios.items()},
                'volume_stats': {
                    'promedio': avg_volume,
                    'hora_pico': peak_volume,
                    'percentil_90': p90_volume,
                    'percentil_75': p75_volume
                },
                'tmo_info': {
                    'promedio_usado': avg_tmo,
                    'pico_usado': peak_tmo,
                    'escenario_pico_corregido': True  # Confirmar correcciÃ³n aplicada
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ Error calculando escenarios: {e}")
            return {}
    
    def _validate_against_reality(self, df: pd.DataFrame, dimensioning_results: Dict) -> Dict:
        """Validar resultados de dimensionamiento contra datos reales"""
        try:
            # EstadÃ­sticas reales de TME
            real_tme_stats = {
                'promedio': df['tme'].mean(),
                'mediana': df['tme'].median(),
                'percentil_90': df['tme'].quantile(0.9),
                'std': df['tme'].std()
            }
            
            # Calcular SLA real (asumiendo objetivo de 20s)
            answer_time_target = 20
            calls_answered_in_time = (df['tme'] <= answer_time_target).sum()
            real_sla = (calls_answered_in_time / len(df)) * 100
            
            # Agentes reales promedio por dÃ­a
            real_agents_per_day = df.groupby('fecha')['asesor'].nunique().mean()
            
            # Comparar con escenarios calculados
            comparisons = {}
            for scenario_name, scenario_results in dimensioning_results['scenarios'].items():
                predicted_wait = scenario_results['average_wait_time']
                predicted_sla = scenario_results['service_level']
                predicted_agents = scenario_results['agents_with_shrinkage']
                
                comparisons[scenario_name] = {
                    'tme_predicho_vs_real': {
                        'predicho': predicted_wait,
                        'real': real_tme_stats['promedio'],
                        'diferencia_absoluta': abs(predicted_wait - real_tme_stats['promedio']),
                        'precision_pct': 100 - abs((predicted_wait - real_tme_stats['promedio']) / real_tme_stats['promedio'] * 100)
                    },
                    'sla_predicho_vs_real': {
                        'predicho': predicted_sla,
                        'real': real_sla,
                        'diferencia_absoluta': abs(predicted_sla - real_sla)
                    },
                    'agentes_predicho_vs_real': {
                        'predicho': predicted_agents,
                        'real': real_agents_per_day,
                        'diferencia': predicted_agents - real_agents_per_day
                    }
                }
            
            return {
                'real_stats': {
                    'tme_stats': real_tme_stats,
                    'sla_real': real_sla,
                    'agentes_promedio_dia': real_agents_per_day,
                    'total_llamadas_analizadas': len(df)
                },
                'comparisons': comparisons,
                'best_scenario': self._find_best_scenario(comparisons)
            }
            
        except Exception as e:
            logger.error(f"âŒ Error en validaciÃ³n: {e}")
            return {}
    
    def _find_best_scenario(self, comparisons: Dict) -> Dict:
        """Encontrar el escenario con mejor precisiÃ³n"""
        try:
            best_scenario = None
            best_precision = -1
            
            for scenario_name, comparison in comparisons.items():
                precision = comparison['tme_predicho_vs_real']['precision_pct']
                if precision > best_precision:
                    best_precision = precision
                    best_scenario = scenario_name
            
            return {
                'nombre': best_scenario,
                'precision_tme': best_precision,
                'detalles': comparisons.get(best_scenario, {})
            }
            
        except Exception as e:
            logger.error(f"âŒ Error encontrando mejor escenario: {e}")
            return {}
    
    def _generate_recommendations(self, historical_analysis: Dict, 
                                dimensioning_results: Dict, 
                                validation_results: Dict) -> Dict:
        """Generar recomendaciones basadas en el anÃ¡lisis"""
        try:
            recommendations = {
                'dimensionamiento': [],
                'operacional': [],
                'mejoras': []
            }
            
            best_scenario = validation_results.get('best_scenario', {})
            
            # Recomendaciones de dimensionamiento
            if best_scenario.get('nombre'):
                scenario_name = best_scenario['nombre']
                scenario_data = dimensioning_results['scenarios'][scenario_name]
                
                recommendations['dimensionamiento'].append({
                    'tipo': 'Escenario Recomendado',
                    'descripcion': f"Usar escenario '{scenario_name}' como base",
                    'agentes_recomendados': scenario_data['agents_with_shrinkage'],
                    'justificacion': f"Mejor precisiÃ³n TME: {best_scenario['precision_tme']:.1f}%"
                })
            
            # Recomendaciones operacionales
            peak_hour = historical_analysis['volume_analysis']['peak_hour']
            recommendations['operacional'].append({
                'tipo': 'Horario CrÃ­tico',
                'descripcion': f"Reforzar dotaciÃ³n en hora {peak_hour}h",
                'detalle': f"Volumen pico: {historical_analysis['volume_analysis']['peak_volume']} llamadas/hora"
            })
            
            # AnÃ¡lisis de TMO
            avg_tmo = historical_analysis['tmo_analysis']['average_seconds']
            if avg_tmo > 300:  # MÃ¡s de 5 minutos
                recommendations['mejoras'].append({
                    'tipo': 'OptimizaciÃ³n TMO',
                    'descripcion': f"TMO promedio alto: {avg_tmo:.0f}s",
                    'sugerencia': 'Considerar capacitaciÃ³n para reducir tiempo de manejo'
                })
            
            return recommendations
            
        except Exception as e:
            logger.error(f"âŒ Error generando recomendaciones: {e}")
            return {}
    
    def _create_executive_summary(self, historical_analysis: Dict, 
                                dimensioning_results: Dict, 
                                validation_results: Dict) -> Dict:
        """Crear resumen ejecutivo"""
        try:
            best_scenario = validation_results.get('best_scenario', {})
            scenario_name = best_scenario.get('nombre', 'promedio')
            recommended_scenario = dimensioning_results['scenarios'][scenario_name]
            
            return {
                'agentes_recomendados': recommended_scenario['agents_with_shrinkage'],
                'escenario_base': scenario_name,
                'precision_modelo': best_scenario.get('precision_tme', 0),
                'volumen_analizado': historical_analysis['total_calls'],
                'periodo_dias': historical_analysis['date_range']['days'],
                'sla_actual_estimado': validation_results['real_stats']['sla_real'],
                'tme_promedio_real': validation_results['real_stats']['tme_stats']['promedio'],
                'agentes_actuales_promedio': validation_results['real_stats']['agentes_promedio_dia']
            }
            
        except Exception as e:
            logger.error(f"âŒ Error creando resumen ejecutivo: {e}")
            return {}
    
    def _log_complete_results(self, analysis: Dict):
        """Log completo de resultados"""
        try:
            print("\n" + "="*80)
            print("ğŸ“Š RESUMEN EJECUTIVO - ANÃLISIS COMPLETO")
            print("="*80)
            
            summary = analysis['summary']
            print(f"ğŸ“… PerÃ­odo analizado: {analysis['period']['days_analyzed']} dÃ­as")
            print(f"ğŸ“ Llamadas analizadas: {summary['volumen_analizado']:,}")
            print(f"ğŸ‘¥ Agentes recomendados: {summary['agentes_recomendados']}")
            print(f"ğŸ¯ Escenario base: {summary['escenario_base']}")
            print(f"âœ… PrecisiÃ³n del modelo: {summary['precision_modelo']:.1f}%")
            print(f"ğŸ“ˆ SLA actual estimado: {summary['sla_actual_estimado']:.1f}%")
            print(f"â³ TME promedio real: {summary['tme_promedio_real']:.1f}s")
            print(f"ğŸ‘¥ Agentes actuales promedio: {summary['agentes_actuales_promedio']:.1f}")
            
            print("\nğŸ“‹ ESCENARIOS CALCULADOS:")
            for scenario_name, scenario_data in analysis['dimensioning_results']['scenarios'].items():
                print(f"   {scenario_name.upper()}: {scenario_data['agents_with_shrinkage']} agentes | SL: {scenario_data['service_level']:.1f}%")
            
            print("\nğŸ’¡ RECOMENDACIONES PRINCIPALES:")
            for rec in analysis['recommendations']['dimensionamiento']:
                print(f"   â€¢ {rec['descripcion']}")
            
            print("="*80)
            
        except Exception as e:
            logger.error(f"âŒ Error en log de resultados: {e}")

# Instancia global
data_analyzer = DataAnalyzer()

def test_integration():
    """Test de integraciÃ³n completo"""
    print("ğŸ§ª Iniciando test de integraciÃ³n SQL + Erlang C...")
    
    try:
        # Usar fechas de los datos disponibles
        start_date = date(2025, 5, 15)
        end_date = date(2025, 5, 16)
        
        print(f"ğŸ“… Analizando perÃ­odo: {start_date} - {end_date}")
        
        # Ejecutar anÃ¡lisis completo
        results = data_analyzer.analyze_campaign_complete(
            start_date=start_date,
            end_date=end_date,
            sla_target=0.90,
            answer_time_target=20,
            shrinkage_pct=15.0
        )
        
        print("\nâœ… Test de integraciÃ³n completado exitosamente")
        return True
        
    except Exception as e:
        print(f"âŒ Test de integraciÃ³n fallido: {e}")
        logger.error(f"âŒ Test de integraciÃ³n fallido: {e}")
        return False

if __name__ == "__main__":
    # Ejecutar test de integraciÃ³n
    test_integration()